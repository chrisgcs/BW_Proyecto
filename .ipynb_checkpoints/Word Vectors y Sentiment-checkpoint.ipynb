{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import gensim.models.wrappers.fasttext\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../fastext aligned/wiki.en.align.vec', binary=False, encoding='utf8')\n",
    "word_vectors = model.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.7321166396141052),\n",
       " ('kitten', 0.6452998518943787),\n",
       " ('dog', 0.6380450129508972),\n",
       " ('kittens', 0.6217814087867737),\n",
       " ('feline', 0.6106876730918884),\n",
       " ('cat/dog', 0.5801181793212891),\n",
       " ('pet', 0.5726068019866943),\n",
       " ('fluffykittens', 0.5583418607711792),\n",
       " ('poodle', 0.5575973391532898),\n",
       " ('felines', 0.5575810670852661)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(\"cat\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x11d169b70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../fastext aligned/bin/wiki.en.align.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load('../fastext aligned/bin/wiki.en.align.bin', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([-0.0327,  0.0332, -0.0772,  0.0275, -0.0469,  0.1078,  0.0504,\n",
       "        -0.1214,  0.008 ,  0.0365,  0.0359, -0.0007,  0.0465, -0.0417,\n",
       "         0.0666, -0.0216,  0.0181, -0.1038,  0.0469,  0.0666,  0.0023,\n",
       "         0.1221, -0.0987,  0.0255,  0.0834,  0.0058, -0.0176,  0.063 ,\n",
       "         0.0798,  0.1121,  0.0639,  0.0554,  0.0276, -0.0525,  0.0444,\n",
       "        -0.024 , -0.0154, -0.0101,  0.0151, -0.0066, -0.0261, -0.0619,\n",
       "        -0.0529, -0.0088,  0.0302,  0.1228, -0.0194, -0.0926,  0.0387,\n",
       "        -0.0696,  0.022 , -0.0141, -0.0218, -0.0827,  0.0747,  0.0894,\n",
       "         0.0022, -0.1003,  0.0178,  0.0456,  0.0493, -0.112 ,  0.0222,\n",
       "         0.0507, -0.0145, -0.0894,  0.0295, -0.0067, -0.0302,  0.0112,\n",
       "        -0.0122, -0.0821,  0.0589, -0.0976, -0.0933,  0.0064, -0.0399,\n",
       "         0.0827, -0.0884,  0.0282, -0.0162,  0.003 ,  0.0447,  0.0874,\n",
       "         0.0849,  0.027 , -0.0394,  0.0112,  0.0571,  0.0149,  0.0287,\n",
       "        -0.046 ,  0.0819,  0.034 ,  0.0254,  0.0362, -0.066 , -0.0593,\n",
       "        -0.0612,  0.0117,  0.0418,  0.02  , -0.0587,  0.0297,  0.0097,\n",
       "        -0.0552,  0.0519,  0.0018,  0.0614, -0.0462,  0.0485, -0.0071,\n",
       "        -0.0751, -0.0124,  0.0113, -0.0366,  0.0226, -0.0462,  0.0358,\n",
       "        -0.032 , -0.0096, -0.0332,  0.0122,  0.0568,  0.0368,  0.0305,\n",
       "         0.123 ,  0.0067,  0.0736,  0.1161, -0.07  ,  0.0352, -0.0601,\n",
       "         0.0728,  0.0064, -0.0252,  0.0347, -0.0398, -0.1045,  0.0729,\n",
       "         0.0237,  0.0226,  0.047 ,  0.0257, -0.017 ,  0.0345, -0.0016,\n",
       "        -0.0457, -0.0044,  0.0682, -0.0312, -0.0625, -0.107 , -0.0309,\n",
       "         0.0345,  0.0211,  0.0607, -0.0262, -0.0034,  0.071 ,  0.0298,\n",
       "         0.0076, -0.0665,  0.0387,  0.0284, -0.049 , -0.0366, -0.0551,\n",
       "         0.0258,  0.0321, -0.0131, -0.1178, -0.0299, -0.0204,  0.0393,\n",
       "        -0.0064, -0.0198, -0.0868,  0.0114, -0.0491, -0.0421, -0.0674,\n",
       "         0.1151, -0.0756, -0.0149, -0.0024,  0.0092, -0.016 ,  0.0107,\n",
       "         0.1034, -0.002 , -0.0847, -0.01  ,  0.0823, -0.0829, -0.121 ,\n",
       "        -0.1081, -0.0757, -0.1805, -0.0399,  0.0276,  0.0227,  0.0257,\n",
       "         0.0088,  0.0037, -0.1552, -0.0029, -0.1443, -0.0511, -0.0628,\n",
       "         0.0472, -0.0561,  0.0463, -0.0303,  0.0545, -0.0201,  0.0839,\n",
       "        -0.0049, -0.0536, -0.0332, -0.0169, -0.0503, -0.1271,  0.0587,\n",
       "        -0.032 , -0.0206, -0.0345, -0.006 ,  0.0351,  0.0569,  0.0319,\n",
       "         0.0604, -0.0113, -0.0104,  0.0121,  0.0873, -0.0574,  0.0394,\n",
       "        -0.0159,  0.0671, -0.0176,  0.1006,  0.0725,  0.0796, -0.0054,\n",
       "         0.0032, -0.0566,  0.0603, -0.0502,  0.1274,  0.0282, -0.066 ,\n",
       "        -0.124 ,  0.0628,  0.0281, -0.0581,  0.0478, -0.0185,  0.0708,\n",
       "        -0.0545, -0.0044,  0.011 ,  0.0163, -0.0526, -0.0956, -0.0106,\n",
       "         0.0189,  0.0066,  0.0164, -0.0195, -0.0481, -0.0175,  0.0903,\n",
       "        -0.098 ,  0.004 , -0.142 , -0.0038, -0.061 ,  0.0866,  0.0628,\n",
       "         0.0858,  0.0176,  0.0767,  0.0346,  0.0949,  0.0192,  0.0062,\n",
       "         0.0487, -0.1055, -0.0334,  0.036 , -0.0774,  0.0243, -0.0126,\n",
       "        -0.0163, -0.0016, -0.0158,  0.0647,  0.1231, -0.0021],\n",
       "       dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_es= gensim.models.KeyedVectors.load_word2vec_format('../fastext aligned/wiki.es.align.vec', binary=False, encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_es.save('../fastext aligned/bin/wiki.es.align.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_vectors2 = KeyedVectors.load('../fastext aligned/bin/wiki.es.align.bin', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gato', 0.5217772722244263)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors2.most_similar(positive=[word_vectors['cat']],topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar Binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load('../fastext aligned/bin/wiki.en.align.bin', mmap='r')\n",
    "word_vectors2 = KeyedVectors.load('../fastext aligned/bin/wiki.es.align.bin', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"twits_cop25_results_en_es.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', 1)\n",
    "df = df.drop('created_at', 1)\n",
    "df = df.drop('geo', 1)\n",
    "df = df.drop('near', 1)\n",
    "df = df.drop('source', 1)\n",
    "df = df.drop('user_rt_id', 1)\n",
    "df = df.drop('user_rt', 1)       \n",
    "df = df.drop('retweet_id', 1)\n",
    "df = df.drop('retweet_date', 1)\n",
    "df = df.drop('translate', 1)\n",
    "df = df.drop('trans_src', 1)\n",
    "df = df.drop('trans_dest', 1)\n",
    "df = df.drop('quote_url', 1)\n",
    "df = df.drop('place', 1)\n",
    "df = df.drop('video', 1)\n",
    "df = df.drop('username', 1)\n",
    "df = df.drop('name', 1)\n",
    "df = df.drop('urls', 1)\n",
    "df = df.drop('photos', 1)\n",
    "df = df.drop('replies_count', 1)\n",
    "df = df.drop('cashtags', 1)\n",
    "df = df.drop('link', 1)\n",
    "df = df.drop('retweet', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124524 entries, 0 to 124523\n",
      "Data columns (total 11 columns):\n",
      "conversation_id    124524 non-null int64\n",
      "date               124524 non-null object\n",
      "time               124524 non-null object\n",
      "timezone           124524 non-null int64\n",
      "user_id            124524 non-null int64\n",
      "tweet              124524 non-null object\n",
      "mentions           124524 non-null object\n",
      "retweets_count     124524 non-null int64\n",
      "likes_count        124524 non-null int64\n",
      "hashtags           124524 non-null object\n",
      "reply_to           124524 non-null object\n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chile = pd.read_csv(\"twits_cop25chile_results_en_es.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chile = df_chile.drop('id', 1)\n",
    "df_chile = df_chile.drop('created_at', 1)\n",
    "df_chile = df_chile.drop('geo', 1)\n",
    "df_chile = df_chile.drop('near', 1)\n",
    "df_chile = df_chile.drop('source', 1)\n",
    "df_chile = df_chile.drop('user_rt_id', 1)\n",
    "df_chile = df_chile.drop('user_rt', 1)       \n",
    "df_chile = df_chile.drop('retweet_id', 1)\n",
    "df_chile = df_chile.drop('retweet_date', 1)\n",
    "df_chile = df_chile.drop('translate', 1)\n",
    "df_chile = df_chile.drop('trans_src', 1)\n",
    "df_chile = df_chile.drop('trans_dest', 1)\n",
    "df_chile = df_chile.drop('quote_url', 1)\n",
    "df_chile = df_chile.drop('place', 1)\n",
    "df_chile = df_chile.drop('video', 1)\n",
    "df_chile = df_chile.drop('username', 1)\n",
    "df_chile = df_chile.drop('name', 1)\n",
    "df_chile = df_chile.drop('urls', 1)\n",
    "df_chile = df_chile.drop('photos', 1)\n",
    "df_chile = df_chile.drop('replies_count', 1)\n",
    "df_chile = df_chile.drop('cashtags', 1)\n",
    "df_chile = df_chile.drop('link', 1)\n",
    "df_chile = df_chile.drop('retweet', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42105 entries, 0 to 42104\n",
      "Data columns (total 11 columns):\n",
      "conversation_id    42105 non-null int64\n",
      "date               42105 non-null object\n",
      "time               42105 non-null object\n",
      "timezone           42105 non-null int64\n",
      "user_id            42105 non-null int64\n",
      "tweet              42105 non-null object\n",
      "mentions           42105 non-null object\n",
      "retweets_count     42105 non-null int64\n",
      "likes_count        42105 non-null int64\n",
      "hashtags           42105 non-null object\n",
      "reply_to           42105 non-null object\n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_chile.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tweets = df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photograph', 'hellenvanmeene', 'TIME', 'emergenciaclimatica', 'horadeactuar', 'COP25', 'fridaysforfuture', 'climateprotest', 'ClimateEmergency', 'FridaysForFutureSweden', 'globalclimatestrike', 'GlobalWarming', 'GlobalGoals', 'GlobalStrike', 'globalstrikeforfuture', 'pictwittercomjdc9lTGxLL']\n",
      "Photograph by @hellenvanmeene for TIME -\n",
      "  #emergenciaclimatica #horadeactuar #COP25 #fridaysforfuture #climateprotest #ClimateEmergency #FridaysForFutureSweden #globalclimatestrike #GlobalWarming #GlobalGoals #GlobalStrike #globalstrikeforfuture pic.twitter.com/jdc9lTGxLL\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from cucco import Cucco\n",
    "import numpy as np\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words[:5]\n",
    "cucco = Cucco()\n",
    "suma = np.zeros(300)\n",
    "for i in lista_tweets:\n",
    "    #i = word_tokenize(i)\n",
    "    #l = [w for w in i if not w in stop_words]\n",
    "    l = cucco.normalize(str(i))\n",
    "    l = word_tokenize(l)\n",
    "    l = [w for w in l if not w in stop_words]\n",
    "    print(l)\n",
    "    for word in l:\n",
    "        try:\n",
    "            suma = suma + word_vectors2[word]\n",
    "        except:\n",
    "            continue\n",
    "    print(i)\n",
    "    #print(word_vectors2.similar_by_vector(suma, topn = 5 , restrict_vocab= None))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "nlp = StanfordCoreNLP('tools/stanford-corenlp-full-2018-10-05')\n",
    "def analyzefile(input_file, output_dir):\n",
    "    \"\"\"\n",
    "    Performs sentiment analysis on the text file given as input using the ANEW database.\n",
    "    Outputs results to a new CSV file in output_dir.\n",
    "    :param input_file: path of .txt file to analyze\n",
    "    :param output_dir: path of directory to create new output file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    output_file = os.path.join(output_dir, \"Output SentiWordNet \" + os.path.basename(input_file).rstrip('txt') + \"csv\")\n",
    "\n",
    "    # read file into string\n",
    "    with open(input_file, 'r', encoding= 'utf-8') as myfile:\n",
    "        fulltext = myfile.read()\n",
    "    # end method if file is empty\n",
    "    if len(fulltext) < 1:\n",
    "        print('Empty file.')\n",
    "        return\n",
    "\n",
    "    from nltk.stem.wordnet import WordNetLemmatizer\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    \n",
    "    sentences = tokenize.sent_tokenize(fulltext)  # split text into sentences\n",
    "    i = 1  # to store sentence index\n",
    "\n",
    "    # check each word in sentence for sentiment and write to output_file\n",
    "    with open(output_file, 'w', newline='', encoding = 'utf-8') as csvfile:\n",
    "        fieldnames = ['Sentence ID', 'Sentence', 'Sentiment', 'Sentiment Label']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # analyze each sentence for sentiment\n",
    "        for s in sentences:\n",
    "            words = nlp.pos_tag(s.lower())\n",
    "            score_list=[]\n",
    "            for idx, t in enumerate(words):\n",
    "                newtag=''\n",
    "                lemmatized=lmtzr.lemmatize(t[0])\n",
    "                if t[1].startswith('NN'):\n",
    "                    newtag='n'\n",
    "                elif t[1].startswith('JJ'):\n",
    "                    newtag='a'\n",
    "                elif t[1].startswith('V'):\n",
    "                    newtag='v'\n",
    "                elif t[1].startswith('R'):\n",
    "                    newtag='r'\n",
    "                else:\n",
    "                    newtag='' \n",
    "                if(newtag!=''):    \n",
    "                    synsets = list(swn.senti_synsets(lemmatized, newtag))#conjunto de sinonimos\n",
    "                    #Getting average of all possible sentiments, as you requested        \n",
    "                    score=0\n",
    "                    if(len(synsets)>0):\n",
    "                        for syn in synsets:\n",
    "                            score+=syn.pos_score()-syn.neg_score()\n",
    "                        score_list.append(score/len(synsets))\n",
    "            try:\n",
    "                sentiment = statistics.mean(score_list)\n",
    "                label = 'neutral'\n",
    "                if sentiment > 0:\n",
    "                    label = 'positive'\n",
    "                elif sentiment < 0:\n",
    "                    label = 'negative'\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            # write to output CSV\n",
    "            writer.writerow({'Sentence ID': i,\n",
    "                             'Sentence': s,\n",
    "                             'Sentiment': sentiment,\n",
    "                             'Sentiment Label': label,\n",
    "                             })\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-143a6592c2a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalyzefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tweets_mundo.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"./\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-2f52d592361d>\u001b[0m in \u001b[0;36manalyzefile\u001b[1;34m(input_file, output_dir)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# analyze each sentence for sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mscore_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mr_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pos'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, annotators, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Connection'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[0mr_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \"\"\"\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    601\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\pyenviroments\\busquedaweb\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "analyzefile(\"tweets_mundo.txt\",\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
